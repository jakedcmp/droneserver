# MAVLink MCP Server

A Python-based Model Context Protocol (MCP) server for AI-powered drone control. Connect LLMs to MAVLink-enabled drones (PX4, ArduPilot) for natural language flight control.

## Features

- ü§ñ **AI-Powered Control**: Use natural language to command drones via GPT-4, Claude, or other LLMs
- üöÅ **MAVLink Compatible**: Works with PX4, ArduPilot, and other MAVLink drones
- üîß **MCP Protocol**: Standard Model Context Protocol for tool integration
- üì° **Network/Serial Support**: Connect via UDP, TCP, or serial ports
- üõ°Ô∏è **Safe Configuration**: Secure handling of connection credentials

## Prerequisites

- **Python 3.10+**
- **uv** package manager ([install here](https://github.com/astral-sh/uv))
- **MAVLink-compatible drone or simulator** with network access (IP address and port)
  - Connection details will be configured in `.env` file
- **OpenAI or Anthropic API key** (for AI agent control)

## Quick Start

### 1. Set Up Your System

**If starting from a fresh Ubuntu 22.04 instance** (AWS, Digital Ocean, Linode, etc.):

```bash
# Update system packages
sudo apt update && sudo apt upgrade -y

# Install essential dependencies
sudo apt install -y python3 python3-pip python3-venv git curl build-essential

# Verify Python version (should be 3.10+)
python3 --version
```

**Install uv package manager:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Restart your shell or load the environment:**

```bash
source $HOME/.bashrc
# Or if using zsh: source $HOME/.zshrc
```

**Verify uv installation:**

```bash
uv --version
```

### 2. Clone and Install

```bash
git clone https://github.com/PeterJBurke/MAVLinkMCP.git
cd MAVLinkMCP
uv sync
```

### 3. Configure Connection and API Keys

**a) Set up drone connection:**

Copy the example configuration:
```bash
cp .env.example .env
```

Edit `.env` with your drone's IP and port:
```bash
nano .env
```

Set your drone's connection details:
```bash
MAVLINK_ADDRESS=<your-drone-ip>
MAVLINK_PORT=14540  # Or your drone's specific port
```

**Save and exit:** Press `Ctrl+X`, then `Y`, then `Enter`

**b) Add your API key:**

Create the secrets file:
```bash
nano examples/fastagent.secrets.yaml
```

Add your OpenAI or Anthropic API key:
```yaml
openai:
    api_key: sk-your-actual-openai-key-here
```

Or for Claude:
```yaml
anthropic:
    api_key: sk-ant-your-anthropic-key-here
```

**Save and exit:** Press `Ctrl+X`, then `Y`, then `Enter`

### 4. Run the AI Agent

```bash
uv run examples/example_agent.py
```

**Note:** The agent automatically starts the MCP server - no need to run it separately!

Then use natural language commands:
- "Arm the drone"
- "Take off to 5 meters"
- "What is the current position?"
- "Land the drone"

## Usage

### Method 1: AI Agent (Recommended)

The AI agent provides natural language control. The agent **automatically starts the MCP server** as a subprocess - you don't need to run the server separately.

```bash
# Configure API keys in examples/fastagent.secrets.yaml
uv run examples/example_agent.py
```

### Method 2: Direct MCP Server (Advanced)

For integration with other MCP clients or custom applications. Only use this if you're **not** using the AI agent:

```bash
uv run src/server/mavlinkmcp.py
```

**Note:** This runs the server standalone. The AI agent (Method 1) starts this automatically.

### Quick Launch Scripts

Test connection:
```bash
./test_connection.sh
```

Start agent with auto-configuration:
```bash
./start_agent.sh
```

## Documentation

- **[Deployment Guide](DEPLOYMENT_GUIDE.md)** - Complete setup and usage instructions
- **[Examples README](examples/README.md)** - Example agent documentation
- **[MCP Protocol](https://modelcontextprotocol.io/)** - Model Context Protocol docs
- **[MAVSDK](https://mavsdk.mavlink.io/)** - MAVLink SDK documentation

## Available Tools

The MCP server exposes these tools for drone control:

| Category | Tools |
|----------|-------|
| **Flight Control** | `arm_drone`, `takeoff`, `land`, `move_to_relative` |
| **Telemetry** | `get_position`, `get_flight_mode`, `get_imu`, `print_status_text` |
| **Missions** | `initiate_mission`, `print_mission_progress` |

## Configuration

Create a `.env` file in the project root:

```bash
# Drone connection details
MAVLINK_ADDRESS=<your-drone-ip>  # Your drone IP address
MAVLINK_PORT=14540               # MAVLink port (default: 14540)
```

For the AI agent, create `examples/fastagent.secrets.yaml`:

```yaml
openai:
    api_key: sk-your-key-here
```

## Safety Guidelines

‚ö†Ô∏è **IMPORTANT**: Always follow drone safety protocols:

- Maintain visual line of sight
- Verify GPS lock before flight
- Have manual RC override ready
- Test in open areas away from people
- Check local regulations and weather
- Start with low altitudes (3-5m)

## Development

This project uses `uv` for dependency management:

```bash
# Install dependencies
uv sync

# Run the server
uv run src/server/mavlinkmcp.py

# Run the example agent
uv run examples/example_agent.py

# Add a new dependency
uv add package-name
```

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

MIT License - see [LICENSE](LICENSE) file for details.

## Acknowledgments

- Original project by [Ion Gabriel](https://github.com/ion-g-ion/MAVLinkMCP)
- Built with [MAVSDK](https://mavsdk.mavlink.io/)
- Uses [Model Context Protocol](https://modelcontextprotocol.io/)

## Support

- üìñ [Full Deployment Guide](DEPLOYMENT_GUIDE.md)
- üêõ [Report Issues](https://github.com/PeterJBurke/MAVLinkMCP/issues)
- üí¨ [Discussions](https://github.com/PeterJBurke/MAVLinkMCP/discussions)
